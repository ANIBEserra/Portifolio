name: Credit Guard - Docker & Airflow Infrastructure (Bi-weekly)

on:
  schedule:
    # Runs at 11:50 UTC (08:50 BRT) on the 1st and 15th of each month
    - cron: '50 11 1,15 * *'
  workflow_dispatch: # Allows manual triggering for testing purposes

jobs:
  infrastructure-orchestration:
    name: Run Airflow Orchestration inside Docker
    runs-on: ubuntu-latest

    steps:
      # 1. Clone the repository into the runner
      - name: Checkout Repository
        uses: actions/checkout@v4

      # 2. Set up the GCP credentials file for the container environment
      - name: Setup GCP Credentials
        env:
          GCP_KEY_JSON: ${{ secrets.GCP_SA_KEY }}
        run: |
          # Ensuring the key is placed where the Docker volume mapping expects it
          echo "$GCP_KEY_JSON" > projetos/data_engineering/credit_guard_ml_pipeline/key-google.json

      # 3. Spin up the full Docker Compose stack
      - name: Spin up Docker Compose
        env:
          GCP_SA_KEY: ${{ secrets.GCP_SA_KEY }} 
        run: |
          cd projetos/data_engineering/credit_guard_ml_pipeline
          docker compose up -d

      # 4. Wait for Airflow to be Ready and Trigger DAG
      - name: Wait and Trigger DAG
        run: |
          cd projetos/data_engineering/credit_guard_ml_pipeline
          
          # 1. Identificar o container do scheduler
          SCHEDULER_CONTAINER=$(docker ps --filter "name=airflow-scheduler" --format "{{.Names}}" | head -n 1)
          echo "Targeting container: $SCHEDULER_CONTAINER"

          # 2. Loop de verificação (Wait-for-it)
          echo "Waiting for Airflow database to be ready..."
          MAX_RETRIES=30
          COUNT=0
          while ! docker exec $SCHEDULER_CONTAINER airflow db check; do
            echo "Airflow is still initializing... ($((++COUNT))/$MAX_RETRIES)"
            if [ $COUNT -ge $MAX_RETRIES ]; then
              echo "Timeout: Airflow took too long to start."
              exit 1
            fi
            sleep 10
          done

          echo "Airflow is READY! Triggering DAG now..."
          
          # 3. Disparar a DAG
          docker exec $SCHEDULER_CONTAINER airflow dags trigger pipeline_ingestao_cnpj
          
          echo "Monitoring logs for 60 seconds..."
          sleep 60
          docker logs $SCHEDULER_CONTAINER --tail 100

      # 5. Clean up the environment to free up runner resources
      - name: Shutdown Infrastructure
        if: always() # Ensures cleanup even if previous steps fail
        run: |
          cd projetos/data_engineering/credit_guard_ml_pipeline
          docker compose down